{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb8c238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar  7 00:55:40 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               On  | 00000000:4D:00.0 Off |                  Off |\n",
      "| 30%   37C    P8              34W / 300W |      2MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d7d241",
   "metadata": {},
   "source": [
    "#### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70098a7b-a582-4fa6-9829-aa607bab85ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -qU transformers \\\n",
    "    accelerate \\\n",
    "    hf_transfer \\\n",
    "    flash-attn \\\n",
    "    langchain \\\n",
    "    langchain_openai \\\n",
    "    langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee3841",
   "metadata": {},
   "source": [
    "#### Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad5910fc-530c-4995-8c00-0ad5ed728fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"<HF_TOKEN>\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"<LANGCHAIN_API_KEY>\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"7BSQLMaster\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d71c1",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57e99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593440f1-06fc-497b-a56f-93b328e99978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time import sleep\n",
    "from operator import itemgetter\n",
    "from IPython.display import Markdown\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain.evaluation import load_evaluator\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langsmith import Client\n",
    "from langchain.smith import RunEvalConfig, arun_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dbabbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_langchain_hugging_face_pipeline(model_name: str):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"flash_attention_2\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=model_name,\n",
    "        rust_remote_code=True,\n",
    "        padding_side=\"left\"\n",
    "    )\n",
    "\n",
    "    pipeline_kwargs = {\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_k\": 100,\n",
    "        \"top_p\":0.90,\n",
    "        \"pad_token_id\": tokenizer.pad_token_id if tokenizer.pad_token_id else tokenizer.eos_token_id\n",
    "    }\n",
    "\n",
    "    pipe = pipeline(\n",
    "        task=\"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        **pipeline_kwargs\n",
    "    )\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863bec33",
   "metadata": {},
   "source": [
    "### Generate questions and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f464c6",
   "metadata": {},
   "source": [
    "#### Triplets {question, context, answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ae0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"\"\"Generate a set of question, context, and answer for querying a SQL database:\n",
    "\n",
    "- **Question**: Pose a human query related to a specific task or information retrieval from a SQL database.\n",
    "- **Context**: Describe the data table structure relevant to the question, using `CREATE TABLE` statements only.\n",
    "- **Answer**: Provide the SQL query that effectively solves the human query, based on the given context.\n",
    "\n",
    "Return a JSON object with `question`, `context`, `answer`.\n",
    "\"\"\"\n",
    "\n",
    "one_shot = \"\"\"```json\n",
    "{\n",
    "  \"question\": \"Find the total revenue generated from orders placed by customers in the USA for each product category in the year 2022.\",\n",
    "  \"context\": \"CREATE TABLE Customers (\\n  CustomerID INT PRIMARY KEY,\\n  CustomerName VARCHAR(50),\\n  Country VARCHAR(50)\\n);\\n\\nCREATE TABLE Orders (\\n  OrderID INT PRIMARY KEY,\\n  CustomerID INT,\\n  OrderDate DATE,\\n  FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)\\n);\\n\\nCREATE TABLE OrderDetails (\\n  OrderDetailID INT PRIMARY KEY,\\n  OrderID INT,\\n  ProductID INT,\\n  Quantity INT,\\n  FOREIGN KEY (OrderID) REFERENCES Orders(OrderID),\\n  FOREIGN KEY (ProductID) REFERENCES Products(ProductID) \\n);\\n\\nCREATE TABLE Products (\\n  ProductID INT PRIMARY KEY,\\n  ProductName VARCHAR(100),\\n  CategoryID INT,\\n  Price DECIMAL(10,2),\\n  FOREIGN KEY (CategoryID) REFERENCES Categories(CategoryID)\\n);\\n\\nCREATE TABLE Categories (\\n  CategoryID INT PRIMARY KEY,\\n  CategoryName VARCHAR(50)\\n);\",\n",
    "  \"answer\": \"SELECT c.CategoryName, SUM(p.Price * od.Quantity) AS TotalRevenue\\nFROM OrderDetails od\\nJOIN Orders o ON od.OrderID = o.OrderID\\nJOIN Customers cu ON o.CustomerID = cu.CustomerID\\nJOIN Products p ON od.ProductID = p.ProductID  \\nJOIN Categories c ON p.CategoryID = c.CategoryID\\nWHERE cu.Country = 'USA' AND o.OrderDate BETWEEN '2022-01-01' AND '2022-12-31'\\nGROUP BY c.CategoryName;\"\n",
    "}\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1835d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    HumanMessage(content=user),\n",
    "    AIMessage(content=one_shot),\n",
    "    human_template\n",
    "])\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-0125-preview\",\n",
    "    temperature=0.8,\n",
    ")\n",
    "parser = SimpleJsonOutputParser()\n",
    "chain = template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de0bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tracing_v2_enabled(project_name=\"Triplets Generation\"):\n",
    "#     triplets = await chain.abatch([{\"user_input\": user}] * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c4e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(triplets)\n",
    "# triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cdc2fc",
   "metadata": {},
   "source": [
    "#### Langsmith Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abb71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "dataset_name = \"SQL Triplets - GPT4 Turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c6baf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists\n"
     ]
    }
   ],
   "source": [
    "if client.has_dataset(dataset_name=dataset_name):\n",
    "    print(\"Dataset already exists\")\n",
    "else: \n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        description=\"Questions and answers to evaluate fine tuned SQL models.\",\n",
    "    )\n",
    "    for triplet in triplets:\n",
    "        client.create_example(\n",
    "            inputs={k: v for k, v in triplet.items() if k != \"answer\"},\n",
    "            outputs={k: v for k, v in triplet.items() if k == \"answer\"},\n",
    "            dataset_id=dataset.id,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87331a73",
   "metadata": {},
   "source": [
    "### Evaluate Fine Tuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a8532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "\n",
    "### Input:\n",
    "`{question}`\n",
    "\n",
    "### Context:\n",
    "`{context}`\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "initial_chain = (\n",
    "    {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "    | prompt \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0d1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        RunEvalConfig.EmbeddingDistance(\n",
    "            embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=512),\n",
    "            distance_metric=\"cosine\",\n",
    "            reference_key=\"answer\",\n",
    "            prediction_key=\"output\",\n",
    "            input_key=\"context\" # Not sure about this one\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e683a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_owner = \"jjovalle99/\"\n",
    "models = [\"llama7b-ft-lora-sql-v2\", \"deci7b-ft-lora-sql-v2\", \"mistral7b-ft-lora-sql-v2\", \"gemma7b-ft-lora-sql-v2\"]\n",
    "models = [hf_owner + model for model in models]\n",
    "names = [\"Llama2\", \"DeciLM\", \"Mistral\", \"Gemma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24d5480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Llama2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ed76e342ed4ae1bfab5199165497d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1857e1d4000c417bb1f44773105a1f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878d345de561436e8457b42d1ec7f321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848481af0d52460289817b4462f61084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b920dad468424894b0bac1ebb784de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe760709c0b64a22aacabb760894505d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c593fe97694c41ab4a582d1fec407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014b154e30914a9288dc97a8a7cb9646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b47df4f4f0f4f3a9cde4fa7921a3f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e055d8ec132240e180f4ee0fa1754cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bbf97b8cde4701bb0f0ee2f047d84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Complete!\n",
      "Evaluating Llama2...\n",
      "View the evaluation results for project '7BSQLMaster - Llama2' at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404/compare?selectedSessions=54b286af-5167-4e66-a1d9-e2f3e20c14b3\n",
      "\n",
      "View all tests for Dataset SQL Triplets - GPT4 Turbo at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404\n",
      "[---->                                             ] 1/10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 10/10Evaluation complete...\n",
      "Loading DeciLM...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e725ce2649c4da8a07602296ae6048a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ce03d51de1442eaa19fa97d955fd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_decilm.py:   0%|          | 0.00/576 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df7a719ad394294a20e7176f5176635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)sformers_v4_35_2__configuration_llama.py:   0%|          | 0.00/9.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- transformers_v4_35_2__configuration_llama.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de9b4a8562e4527abd816ab557a142c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "version_check.py:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- version_check.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- configuration_decilm.py\n",
      "- transformers_v4_35_2__configuration_llama.py\n",
      "- version_check.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16af062244df4b8f983425f6d030e542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_decilm.py:   0%|          | 0.00/14.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ad232a63534bdcbb9bcaf500146ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ers_v4_35_2__modeling_attn_mask_utils.py:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- transformers_v4_35_2__modeling_attn_mask_utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d17e4a35dc47bf8121450b39ea7a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transformers_v4_35_2__modeling_llama.py:   0%|          | 0.00/56.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- transformers_v4_35_2__modeling_llama.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/Deci/DeciLM-7B:\n",
      "- modeling_decilm.py\n",
      "- transformers_v4_35_2__modeling_attn_mask_utils.py\n",
      "- transformers_v4_35_2__modeling_llama.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0149debb0d65404aa41903a99e159333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004d57d2cf37448aba4ef5eec7b8a979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592b753343d749549442c65b7a873f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6367ebb3caaf4cc3b1ab62bab5b85059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d7b274c2bc416a8fdc5e011e7d19a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a61acf7c12449a827332e282669163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b96a3a4c6be46af9dba97d613a791a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2260e4d748ba474db81cfff1feeabee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c925af5418eb48668c8ae1fbed17df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b6f6dc097f477ea6d3514d669a37dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Complete!\n",
      "Evaluating DeciLM...\n",
      "View the evaluation results for project '7BSQLMaster - DeciLM' at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404/compare?selectedSessions=13913ff5-14df-4a1e-a533-f04054f49862\n",
      "\n",
      "View all tests for Dataset SQL Triplets - GPT4 Turbo at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404\n",
      "[------------------------------------------------->] 10/10Evaluation complete...\n",
      "Loading Mistral...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d15daefe9a48a7a6683f7f26f2dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752880c4429c428d8f97ed3259fcbd88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53952dc0109a4b42956094e05226e463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb295a9a38d343d6bfa2c2dbb25dc882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32fe4cf1c92463f9a3753976de49625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168afe4787234f3db52f5f2f5619b892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17239a33fa9a4354bf75af98da268136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcb03c37eef47788089ad81c8b2a8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8febf8bebfba47e68e415619da4ddbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d71f94dfba44a88a5b516f72b99efc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cef0e88ac44c21abf858082a02ba2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Complete!\n",
      "Evaluating Mistral...\n",
      "View the evaluation results for project '7BSQLMaster - Mistral' at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404/compare?selectedSessions=b8411566-51b9-46d1-bcb5-0e18fd5965f6\n",
      "\n",
      "View all tests for Dataset SQL Triplets - GPT4 Turbo at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404\n",
      "[------------------------------------------------->] 10/10Evaluation complete...\n",
      "Loading Gemma...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a35f680124941e3bf46630069336f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c45910a31ca48e3a128e7f46aeba783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c897f6b0a0c46c08cef165c945baf1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b1b0621b7f4f61a3068ed7a55cca42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7956c3a8d094edcb77aa7d5db6c241b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9db659028ea4756968a69851410b0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc92e4fce054a748917ced103529925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/2.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dadf73ccbd24b339793967d7815b0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21699623bfd84f07adf18cfb179ceb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7237c6b49ed84ce8ba7a8db6914a5c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074cf61cecc84d118456016db8bd32fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b191198731b496687d2d269b6425769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/555 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Complete!\n",
      "Evaluating Gemma...\n",
      "View the evaluation results for project '7BSQLMaster - Gemma' at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404/compare?selectedSessions=b72cfbd7-be15-4522-bf6f-a353ff756c41\n",
      "\n",
      "View all tests for Dataset SQL Triplets - GPT4 Turbo at:\n",
      "https://smith.langchain.com/o/e1ff5e9a-fc1a-5ec0-91dc-86daf509e790/datasets/bc80884d-83c6-400e-a232-81cdb1553404\n",
      "[------------------------------------------------->] 10/10Evaluation complete...\n"
     ]
    }
   ],
   "source": [
    "for name, model_name in zip(names, models):\n",
    "\n",
    "    print(f\"Loading {name}...\")\n",
    "    hf_pipeline = load_langchain_hugging_face_pipeline(model_name=model_name)\n",
    "    chain = initial_chain | hf_pipeline\n",
    "    print(f\"Load Complete!\")\n",
    "\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    await arun_on_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        llm_or_chain_factory=chain,\n",
    "        evaluation=evaluation_config,\n",
    "        client=client,\n",
    "        project_name=f\"7BSQLMaster - {name}\",\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Evaluation complete...\")\n",
    "\n",
    "    del chain\n",
    "    del hf_pipeline\n",
    "    torch.cuda.empty_cache()\n",
    "    sleep(10)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
